{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d7db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1949943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\anaconda\\lib\\site-packages (0.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd9398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9645ae77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wine_quality.data.features\n",
    "y = wine_quality.data.targets\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7ac78",
   "metadata": {},
   "source": [
    "import statsmodels.api as sm\n",
    "def backward_elemination(data,target,significance_level):\n",
    "    features = data.columns.tolist()\n",
    "    while(len(features)>0):\n",
    "        features_with_constant = sm.add_constant(data[features])\n",
    "        p_values = sm.OLS(target, features_with_constant).fit().pvalues[1:]\n",
    "        max_p_values = p_values.max()\n",
    "        if(max_p_values >= significance_level):\n",
    "            excluded_feature = p_values.idmax()\n",
    "            features.remove(excluded_feature)\n",
    "        else :\n",
    "            break\n",
    "    return features\n",
    "backward_elemination(x,y,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85709839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a07d9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8870d4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5522, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test, y_train , y_test = train_test_split(x,y,test_size=0.15,random_state=0)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8220daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce2bb4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.2930489486628255\n",
      "Test Score:  0.2861082684067934\n"
     ]
    }
   ],
   "source": [
    "#Checking the score  \n",
    "print('Train Score: ', reg.score(x_train, y_train))  \n",
    "print('Test Score: ', reg.score(x_test, y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e7de38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = reg.predict(x_test)\n",
    "round(y_predict[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b45c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 7, 6, 5, 5, 6, 7, 6,\n",
       "       6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 7, 6, 6, 6, 6, 7, 6, 6, 5, 6, 5, 6,\n",
       "       6, 5, 6, 5, 5, 6, 5, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 7, 7,\n",
       "       6, 5, 6, 6, 6, 5, 5, 6, 7, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5,\n",
       "       5, 6, 5, 6, 6, 6, 5, 6, 7, 6, 5, 6, 6, 5, 6, 5, 6, 6, 5, 6, 6, 5,\n",
       "       6, 6, 5, 7, 6, 6, 5, 5, 7, 6, 5, 7, 7, 6, 6, 5, 6, 6, 5, 6, 6, 6,\n",
       "       5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 7,\n",
       "       6, 6, 6, 7, 6, 7, 6, 6, 6, 7, 5, 6, 5, 5, 6, 6, 6, 5, 6, 7, 6, 6,\n",
       "       5, 5, 7, 6, 5, 6, 6, 7, 6, 6, 5, 6, 6, 7, 6, 6, 6, 5, 6, 6, 6, 6,\n",
       "       6, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6,\n",
       "       6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 5, 6, 6, 5,\n",
       "       6, 6, 7, 6, 6, 6, 5, 7, 6, 6, 5, 6, 6, 5, 6, 6, 7, 7, 6, 5, 6, 6,\n",
       "       5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 6, 6, 6, 7, 6, 6, 7, 6, 5, 7, 6,\n",
       "       6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 7, 6, 7, 7, 6, 6, 6, 6, 5, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 5, 6, 7, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5,\n",
       "       6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 6, 6,\n",
       "       6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 7, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6,\n",
       "       6, 7, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 6, 7, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 5, 5, 6, 5, 7, 7, 6, 6, 7, 6, 6,\n",
       "       6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 7, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5,\n",
       "       6, 6, 5, 5, 6, 5, 6, 5, 6, 7, 7, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6,\n",
       "       5, 6, 6, 7, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 6, 6, 5, 6,\n",
       "       5, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 5, 5, 7, 5, 6, 5, 5, 6, 7,\n",
       "       6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 6, 7, 5, 6, 6, 6, 6, 6, 5,\n",
       "       6, 5, 6, 5, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6,\n",
       "       6, 6, 5, 5, 5, 6, 5, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 7, 5, 6, 6,\n",
       "       6, 5, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 7, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       7, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 5, 5, 6, 5, 5, 6, 5, 7, 6, 5,\n",
       "       6, 5, 6, 5, 7, 6, 6, 7, 5, 6, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 6, 6,\n",
       "       6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 7, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 6, 5, 7, 6, 5, 6, 6, 6, 6, 6,\n",
       "       6, 6, 7, 6, 5, 5, 5, 6, 6, 7, 6, 6, 5, 6, 6, 5, 6, 7, 6, 6, 6, 5,\n",
       "       6, 6, 6, 5, 6, 6, 7, 5, 5, 5, 6, 6, 7, 5, 7, 5, 7, 6, 5, 5, 6, 6,\n",
       "       6, 6, 6, 6, 5, 6, 6, 7, 6, 6, 6, 6, 7, 7, 6, 6, 7, 6, 5, 6, 6, 6,\n",
       "       6, 6, 6, 5, 6, 6, 6, 6, 7, 7, 7, 6, 5, 6, 6, 5, 6, 6, 7, 6, 6, 5,\n",
       "       6, 5, 6, 7, 6, 5, 6, 5, 6, 7, 5, 6, 6, 5, 6, 5, 7, 6, 6, 6, 6, 6,\n",
       "       6, 5, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 7, 6, 5, 7, 6, 5, 7, 6, 6, 6,\n",
       "       5, 6, 6, 6, 7, 6, 6, 6, 5, 5, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 5, 5, 5, 6, 7, 6, 6, 6, 7, 6, 6,\n",
       "       6, 5, 6, 6, 5, 7, 5, 6, 5, 6, 7, 5, 6, 6, 6, 7, 6, 6, 5, 6, 5, 5,\n",
       "       6, 5, 6, 6, 5, 7, 6, 6, 6, 6, 6, 5, 7, 6, 6, 6, 5, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 5, 7, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 6, 6, 5, 6, 5, 5, 5,\n",
       "       6, 5, 6, 6, 6, 5, 6, 6, 7, 7, 6, 6, 5, 6, 7, 6, 6, 5, 6, 6, 6, 6,\n",
       "       6, 5, 6, 6, 6, 6, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_round = []\n",
    "for i in range(len(y_predict)):\n",
    "    y_predict_round.append(round(y_predict[i][0]))\n",
    "y_predict_round = np.array(y_predict_round)\n",
    "y_predict_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5274ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8956a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,mean_absolute_error,r2_score,confusion_matrix\n",
    "mean_absolute_error(y_test,y_predict_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f448dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087179487179487"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_predict_round,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a0aa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   0,   0,   0,   0],\n",
       "       [  3,  18, 135,  77,   8,   0,   0],\n",
       "       [  2,  16, 166, 323, 114,  21,   0],\n",
       "       [  0,   0,   1,  41,  38,  10,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predict_round,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188896ae",
   "metadata": {},
   "source": [
    "### After BACKWARD Elemination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e08f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.append(arr = np.ones((6497, 1)).astype(int), values=x, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ec274ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f719158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.291</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   243.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:20:02</td>     <th>  Log-Likelihood:    </th> <td> -7215.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6497</td>      <th>  AIC:               </th> <td>1.445e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6485</td>      <th>  BIC:               </th> <td>1.454e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.1683</td> <td>    0.078</td> <td>   66.422</td> <td> 0.000</td> <td>    5.016</td> <td>    5.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8190</td> <td>    0.188</td> <td>    4.346</td> <td> 0.000</td> <td>    0.450</td> <td>    1.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.9918</td> <td>    0.116</td> <td>  -17.162</td> <td> 0.000</td> <td>   -2.219</td> <td>   -1.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.1820</td> <td>    0.132</td> <td>   -1.377</td> <td> 0.168</td> <td>   -0.441</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.8400</td> <td>    0.336</td> <td>    8.449</td> <td> 0.000</td> <td>    2.181</td> <td>    3.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.2912</td> <td>    0.200</td> <td>   -1.454</td> <td> 0.146</td> <td>   -0.684</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    1.7193</td> <td>    0.216</td> <td>    7.948</td> <td> 0.000</td> <td>    1.295</td> <td>    2.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -1.0769</td> <td>    0.120</td> <td>   -8.969</td> <td> 0.000</td> <td>   -1.312</td> <td>   -0.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -2.8511</td> <td>    0.630</td> <td>   -4.529</td> <td> 0.000</td> <td>   -4.085</td> <td>   -1.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.5667</td> <td>    0.117</td> <td>    4.861</td> <td> 0.000</td> <td>    0.338</td> <td>    0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    1.3675</td> <td>    0.135</td> <td>   10.092</td> <td> 0.000</td> <td>    1.102</td> <td>    1.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    1.8425</td> <td>    0.115</td> <td>   15.963</td> <td> 0.000</td> <td>    1.616</td> <td>    2.069</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>144.075</td> <th>  Durbin-Watson:     </th> <td>   1.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 324.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.006</td>  <th>  Prob(JB):          </th> <td>3.09e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.095</td>  <th>  Cond. No.          </th> <td>    100.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.292\n",
       "Model:                            OLS   Adj. R-squared:                  0.291\n",
       "Method:                 Least Squares   F-statistic:                     243.3\n",
       "Date:                Fri, 22 Dec 2023   Prob (F-statistic):               0.00\n",
       "Time:                        10:20:02   Log-Likelihood:                -7215.5\n",
       "No. Observations:                6497   AIC:                         1.445e+04\n",
       "Df Residuals:                    6485   BIC:                         1.454e+04\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.1683      0.078     66.422      0.000       5.016       5.321\n",
       "x1             0.8190      0.188      4.346      0.000       0.450       1.188\n",
       "x2            -1.9918      0.116    -17.162      0.000      -2.219      -1.764\n",
       "x3            -0.1820      0.132     -1.377      0.168      -0.441       0.077\n",
       "x4             2.8400      0.336      8.449      0.000       2.181       3.499\n",
       "x5            -0.2912      0.200     -1.454      0.146      -0.684       0.101\n",
       "x6             1.7193      0.216      7.948      0.000       1.295       2.143\n",
       "x7            -1.0769      0.120     -8.969      0.000      -1.312      -0.842\n",
       "x8            -2.8511      0.630     -4.529      0.000      -4.085      -1.617\n",
       "x9             0.5667      0.117      4.861      0.000       0.338       0.795\n",
       "x10            1.3675      0.135     10.092      0.000       1.102       1.633\n",
       "x11            1.8425      0.115     15.963      0.000       1.616       2.069\n",
       "==============================================================================\n",
       "Omnibus:                      144.075   Durbin-Watson:                   1.646\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              324.712\n",
       "Skew:                          -0.006   Prob(JB):                     3.09e-71\n",
       "Kurtosis:                       4.095   Cond. No.                         100.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "x_opt=x [:, [0,1,2,3,4,5,6,7,8,9,10,11]]  \n",
    "regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()  \n",
    "regressor_OLS.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af7cbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.291</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:20:42</td>     <th>  Log-Likelihood:    </th> <td> -7217.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6497</td>      <th>  AIC:               </th> <td>1.446e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6487</td>      <th>  BIC:               </th> <td>1.452e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.1341</td> <td>    0.076</td> <td>   67.359</td> <td> 0.000</td> <td>    4.985</td> <td>    5.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8011</td> <td>    0.182</td> <td>    4.412</td> <td> 0.000</td> <td>    0.445</td> <td>    1.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.9564</td> <td>    0.106</td> <td>  -18.445</td> <td> 0.000</td> <td>   -2.164</td> <td>   -1.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    2.9567</td> <td>    0.328</td> <td>    9.024</td> <td> 0.000</td> <td>    2.314</td> <td>    3.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.7089</td> <td>    0.216</td> <td>    7.911</td> <td> 0.000</td> <td>    1.285</td> <td>    2.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.0863</td> <td>    0.118</td> <td>   -9.217</td> <td> 0.000</td> <td>   -1.317</td> <td>   -0.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -3.0820</td> <td>    0.616</td> <td>   -5.004</td> <td> 0.000</td> <td>   -4.289</td> <td>   -1.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.6169</td> <td>    0.114</td> <td>    5.411</td> <td> 0.000</td> <td>    0.393</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    1.3133</td> <td>    0.133</td> <td>    9.903</td> <td> 0.000</td> <td>    1.053</td> <td>    1.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    1.8261</td> <td>    0.115</td> <td>   15.886</td> <td> 0.000</td> <td>    1.601</td> <td>    2.051</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>144.178</td> <th>  Durbin-Watson:     </th> <td>   1.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 325.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.004</td>  <th>  Prob(JB):          </th> <td>2.56e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.096</td>  <th>  Cond. No.          </th> <td>    96.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.292\n",
       "Model:                            OLS   Adj. R-squared:                  0.291\n",
       "Method:                 Least Squares   F-statistic:                     296.7\n",
       "Date:                Fri, 22 Dec 2023   Prob (F-statistic):               0.00\n",
       "Time:                        10:20:42   Log-Likelihood:                -7217.8\n",
       "No. Observations:                6497   AIC:                         1.446e+04\n",
       "Df Residuals:                    6487   BIC:                         1.452e+04\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.1341      0.076     67.359      0.000       4.985       5.283\n",
       "x1             0.8011      0.182      4.412      0.000       0.445       1.157\n",
       "x2            -1.9564      0.106    -18.445      0.000      -2.164      -1.748\n",
       "x3             2.9567      0.328      9.024      0.000       2.314       3.599\n",
       "x4             1.7089      0.216      7.911      0.000       1.285       2.132\n",
       "x5            -1.0863      0.118     -9.217      0.000      -1.317      -0.855\n",
       "x6            -3.0820      0.616     -5.004      0.000      -4.289      -1.875\n",
       "x7             0.6169      0.114      5.411      0.000       0.393       0.840\n",
       "x8             1.3133      0.133      9.903      0.000       1.053       1.573\n",
       "x9             1.8261      0.115     15.886      0.000       1.601       2.051\n",
       "==============================================================================\n",
       "Omnibus:                      144.178   Durbin-Watson:                   1.646\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              325.085\n",
       "Skew:                          -0.004   Prob(JB):                     2.56e-71\n",
       "Kurtosis:                       4.096   Cond. No.                         96.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=x [:, [0,1,2,4,6,7,8,9,10,11]]  \n",
    "regressor_OLS=sm.OLS(endog = y, exog=x_opt).fit()  \n",
    "regressor_OLS.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bf77197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed_acidity  volatile_acidity  residual_sugar  free_sulfur_dioxide  \\\n",
       "0               7.4              0.70             1.9                 11.0   \n",
       "1               7.8              0.88             2.6                 25.0   \n",
       "2               7.8              0.76             2.3                 15.0   \n",
       "3              11.2              0.28             1.9                 17.0   \n",
       "4               7.4              0.70             1.9                 11.0   \n",
       "...             ...               ...             ...                  ...   \n",
       "6492            6.2              0.21             1.6                 24.0   \n",
       "6493            6.6              0.32             8.0                 57.0   \n",
       "6494            6.5              0.24             1.2                 30.0   \n",
       "6495            5.5              0.29             1.1                 20.0   \n",
       "6496            6.0              0.21             0.8                 22.0   \n",
       "\n",
       "      total_sulfur_dioxide  density    pH  sulphates  alcohol  \n",
       "0                     34.0  0.99780  3.51       0.56      9.4  \n",
       "1                     67.0  0.99680  3.20       0.68      9.8  \n",
       "2                     54.0  0.99700  3.26       0.65      9.8  \n",
       "3                     60.0  0.99800  3.16       0.58      9.8  \n",
       "4                     34.0  0.99780  3.51       0.56      9.4  \n",
       "...                    ...      ...   ...        ...      ...  \n",
       "6492                  92.0  0.99114  3.27       0.50     11.2  \n",
       "6493                 168.0  0.99490  3.15       0.46      9.6  \n",
       "6494                 111.0  0.99254  2.99       0.46      9.4  \n",
       "6495                 110.0  0.98869  3.34       0.38     12.8  \n",
       "6496                  98.0  0.98941  3.26       0.32     11.8  \n",
       "\n",
       "[6497 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = wine_quality.data.features\n",
    "y = wine_quality.data.targets\n",
    "x = x.iloc[:,[0,1,3,5,6,7,8,9,10]]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53120320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sc.fit_transform(x)\n",
    "x_train , x_test, y_train , y_test = train_test_split(x,y,test_size=0.15,random_state=0)\n",
    "x_train.shape\n",
    "regressor =  LinearRegression()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3003889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.29251471875762225\n",
      "Test Score:  0.28577360061622537\n"
     ]
    }
   ],
   "source": [
    "#Checking the score  \n",
    "print('Train Score: ', regressor.score(x_train, y_train))  \n",
    "print('Test Score: ', regressor.score(x_test, y_test))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a83e9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_round = []\n",
    "for i in range(len(y_predict)):\n",
    "    y_predict_round.append(round(y_predict[i][0]))\n",
    "y_predict_round = np.array(y_predict_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47c809a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,y_predict_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "010985ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087179487179487"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_predict_round,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d96685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
